{"type": "lattice-land", "lattice-land": "start"}
{"type": "statistics", "statistics": {"configuration": "turbo-gpu-release_v1.2.8_barebones_wac1_4096_aircraft_B737NG-600-02-Anon.json_1cores_132threads_timeout1200000ms_sub_15", "problem": "aircraft-disassembly", "model": "../data/mzn-challenge/2024/aircraft-disassembly/aircraft.mzn", "data_file": "../data/mzn-challenge/2024/aircraft-disassembly/B737NG-600-02-Anon.json.dzn", "mzn_solver": "turbo.gpu.release", "version": "v1.2.8", "timeout_ms": "1200000", "datetime": "2025-03-28T19:09:23.562432", "status": "UNKNOWN", "cores": "1", "threads": "132", "arch": "barebones", "fixpoint": "wac1", "wac1_threshold": "4096"}}
cpu-bind=MASK - x1002c3s5b1n0, task  0  0 [902350]: mask 0x1 set
{"type": "statistics", "statistics": {"paths": 0, "flatBoolVars": 170302, "flatIntVars": 57186, "flatBoolConstraints": 64425, "flatIntConstraints": 184405, "evaluatedReifiedConstraints": 113150, "method": "minimize", "flatTime": 8.81412}}
{"type": "statistics", "statistics": {"command_line": "/net/scratch/hscra/plgrid/plgptalbot/lattice-land/turbo/build/gpu-release/turbo -t 1200000 -n 1 -s -arch barebones -or 132 -sub 15 -stack 0 -fp wac1 -wac1_threshold 4096 -version v1.2.8 -hardware 'helios' -cutnodes 0 /tmp/132739/x1002c3s5b1n0/mznfileG4bZMD.fzn", "parsed_variables": 454765, "parsed_constraints": 533296, "abstract_domain": "pir_itv32_z", "tnf_variables": 964802, "tnf_constraints": 968037, "eliminated_entailed_constraints_fp_iter_1": 2578, "eliminated_equality_constraints_fp_iter_1": 282665, "eliminated_constraints_by_icse_fp_iter_1": 420652, "eliminated_constraints_by_as_fp_iter_1": 3962, "icse_fixpoint_iterations_fp_iter_1": 2, "eliminated_entailed_constraints": 2578, "eliminated_equality_constraints": 282665, "eliminated_constraints_by_icse": 420652, "eliminated_constraints_by_as": 3962, "icse_fixpoint_iterations": 3, "eliminated_variables": 711843, "preprocessing_fixpoint_iterations": 2, "variables_after_simplification": 253021, "constraints_after_simplification": 258180, "preprocessing_time": 18.234}}
{"type": "statistics", "statistics": {"memory_configuration": "global", "shared_mem": 0, "store_mem": 2024240, "propagator_mem": 4131008}}
{"type": "comment", "comment": "% ERROR: CUDA kernel failed due to an illegal memory access. This might be due to a stack overflow because it is too small. Try increasing the stack size with the options -stack. If it does not work, please report it as a bug.\n"}
{"type": "status", "status": "ERROR", "time": 29357}
{"type": "statistics", "statistics": {"nSolutions": 0}}
{"type": "statistics", "statistics": {"heap_memory": 1836386528}}
srun: error: x1002c3s5b1n0: task 0: Exited with exit code 1
{"type": "lattice-land", "lattice-land": "start"}
{"type": "statistics", "statistics": {"configuration": "turbo-gpu-release_v1.2.8_barebones_wac1_4096_aircraft_B737NG-600-02-Anon.json_1cores_132threads_timeout1200000ms_sub_15", "problem": "aircraft-disassembly", "model": "../data/mzn-challenge/2024/aircraft-disassembly/aircraft.mzn", "data_file": "../data/mzn-challenge/2024/aircraft-disassembly/B737NG-600-02-Anon.json.dzn", "mzn_solver": "turbo.gpu.release", "version": "v1.2.8", "timeout_ms": "1200000", "datetime": "2025-03-29T08:28:31.435421", "status": "UNKNOWN", "cores": "1", "threads": "132", "arch": "barebones", "fixpoint": "wac1", "wac1_threshold": "4096"}}
cpu-bind=MASK - x1002c7s2b0n0, task  0  0 [451045]: mask 0x1 set
{"type": "statistics", "statistics": {"paths": 0, "flatBoolVars": 170302, "flatIntVars": 57186, "flatBoolConstraints": 64425, "flatIntConstraints": 184405, "evaluatedReifiedConstraints": 113150, "method": "minimize", "flatTime": 13.6958}}
{"type": "statistics", "statistics": {"command_line": "/net/scratch/hscra/plgrid/plgptalbot/lattice-land/turbo/build/gpu-release/turbo -t 1200000 -n 1 -s -arch barebones -or 132 -sub 15 -stack 0 -fp wac1 -wac1_threshold 4096 -version v1.2.8 -hardware 'helios' -cutnodes 0 /tmp/133141/x1002c7s2b0n0/mznfileFE7bQ5.fzn", "parsed_variables": 454765, "parsed_constraints": 533296, "abstract_domain": "pir_itv32_z", "tnf_variables": 964802, "tnf_constraints": 968037, "eliminated_entailed_constraints_fp_iter_1": 2578, "eliminated_equality_constraints_fp_iter_1": 282665, "eliminated_constraints_by_icse_fp_iter_1": 420652, "eliminated_constraints_by_as_fp_iter_1": 3962, "icse_fixpoint_iterations_fp_iter_1": 2, "eliminated_entailed_constraints": 2578, "eliminated_equality_constraints": 282665, "eliminated_constraints_by_icse": 420652, "eliminated_constraints_by_as": 3962, "icse_fixpoint_iterations": 3, "eliminated_variables": 711843, "preprocessing_fixpoint_iterations": 2, "variables_after_simplification": 253021, "constraints_after_simplification": 258180, "preprocessing_time": 28.073}}
{"type": "statistics", "statistics": {"memory_configuration": "global", "shared_mem": 0, "store_mem": 2024240, "propagator_mem": 4131008}}
{"type": "comment", "comment": "% ERROR: CUDA kernel failed due to an illegal memory access. This might be due to a stack overflow because it is too small. Try increasing the stack size with the options -stack. If it does not work, please report it as a bug.\n"}
{"type": "status", "status": "ERROR", "time": 44807}
{"type": "statistics", "statistics": {"nSolutions": 0}}
{"type": "statistics", "statistics": {"heap_memory": 1836387528}}
srun: error: x1002c7s2b0n0: task 0: Exited with exit code 1
{"type": "lattice-land", "lattice-land": "start"}
{"type": "statistics", "statistics": {"configuration": "turbo-gpu-release_v1.2.8_barebones_wac1_4096_aircraft_B737NG-600-02-Anon.json_1cores_132threads_timeout1200000ms_sub_15", "problem": "aircraft-disassembly", "model": "../data/mzn-challenge/2024/aircraft-disassembly/aircraft.mzn", "data_file": "../data/mzn-challenge/2024/aircraft-disassembly/B737NG-600-02-Anon.json.dzn", "mzn_solver": "turbo.gpu.release", "version": "v1.2.8", "timeout_ms": "1200000", "datetime": "2025-03-29T11:37:14.772738", "status": "UNKNOWN", "cores": "1", "threads": "132", "arch": "barebones", "fixpoint": "wac1", "wac1_threshold": "4096"}}
cpu-bind=MASK - x1002c7s3b0n0, task  0  0 [534722]: mask 0x1 set
{"type": "statistics", "statistics": {"paths": 0, "flatBoolVars": 170302, "flatIntVars": 57186, "flatBoolConstraints": 64425, "flatIntConstraints": 184405, "evaluatedReifiedConstraints": 113150, "method": "minimize", "flatTime": 17.9135}}
{"type": "statistics", "statistics": {"command_line": "/net/scratch/hscra/plgrid/plgptalbot/lattice-land/turbo/build/gpu-release/turbo -t 1200000 -n 1 -s -arch barebones -or 132 -sub 15 -stack 0 -fp wac1 -wac1_threshold 4096 -version v1.2.8 -hardware 'helios' -cutnodes 0 /tmp/133168/x1002c7s3b0n0/mznfileMdxN4k.fzn", "parsed_variables": 454765, "parsed_constraints": 533296, "abstract_domain": "pir_itv32_z", "tnf_variables": 964802, "tnf_constraints": 968037, "eliminated_entailed_constraints_fp_iter_1": 2578, "eliminated_equality_constraints_fp_iter_1": 282665, "eliminated_constraints_by_icse_fp_iter_1": 420652, "eliminated_constraints_by_as_fp_iter_1": 3962, "icse_fixpoint_iterations_fp_iter_1": 2, "eliminated_entailed_constraints": 2578, "eliminated_equality_constraints": 282665, "eliminated_constraints_by_icse": 420652, "eliminated_constraints_by_as": 3962, "icse_fixpoint_iterations": 3, "eliminated_variables": 711843, "preprocessing_fixpoint_iterations": 2, "variables_after_simplification": 253021, "constraints_after_simplification": 258180, "preprocessing_time": 28.08}}
{"type": "statistics", "statistics": {"memory_configuration": "global", "shared_mem": 0, "store_mem": 2024240, "propagator_mem": 4131008}}
{"type": "comment", "comment": "% ERROR: CUDA kernel failed due to an illegal memory access. This might be due to a stack overflow because it is too small. Try increasing the stack size with the options -stack. If it does not work, please report it as a bug.\n"}
{"type": "status", "status": "ERROR", "time": 48881}
{"type": "statistics", "statistics": {"nSolutions": 0}}
{"type": "statistics", "statistics": {"heap_memory": 1836387528}}
srun: error: x1002c7s3b0n0: task 0: Exited with exit code 1
{"type": "lattice-land", "lattice-land": "start"}
{"type": "statistics", "statistics": {"configuration": "turbo-gpu-release_v1.2.8_barebones_wac1_4096_aircraft_B737NG-600-02-Anon.json_1cores_132threads_timeout1200000ms_sub_15", "problem": "aircraft-disassembly", "model": "../data/mzn-challenge/2024/aircraft-disassembly/aircraft.mzn", "data_file": "../data/mzn-challenge/2024/aircraft-disassembly/B737NG-600-02-Anon.json.dzn", "mzn_solver": "turbo.gpu.release", "version": "v1.2.8", "timeout_ms": "1200000", "datetime": "2025-03-29T20:58:52.672069", "status": "UNKNOWN", "cores": "1", "threads": "132", "arch": "barebones", "fixpoint": "wac1", "wac1_threshold": "4096"}}
cpu-bind=MASK - x1002c4s1b1n0, task  0  0 [1189140]: mask 0x1000000000000000000 set
{"type": "statistics", "statistics": {"paths": 0, "flatBoolVars": 170302, "flatIntVars": 57186, "flatBoolConstraints": 64425, "flatIntConstraints": 184405, "evaluatedReifiedConstraints": 113150, "method": "minimize", "flatTime": 14.2832}}
{"type": "statistics", "statistics": {"command_line": "/net/scratch/hscra/plgrid/plgptalbot/lattice-land/turbo/build/gpu-release/turbo -t 1200000 -n 1 -s -arch barebones -or 132 -sub 15 -stack 0 -network_analysis -fp wac1 -wac1_threshold 4096 -version v1.2.8 -hardware 'helios' -cutnodes 0 /tmp/133338/x1002c4s1b1n0/mznfileEw9Eun.fzn", "parsed_variables": 454765, "parsed_constraints": 533296, "abstract_domain": "pir_itv32_z", "tnf_variables": 964802, "tnf_constraints": 968037, "eliminated_entailed_constraints_fp_iter_1": 2578, "eliminated_equality_constraints_fp_iter_1": 282665, "eliminated_constraints_by_icse_fp_iter_1": 420652, "eliminated_constraints_by_as_fp_iter_1": 3962, "icse_fixpoint_iterations_fp_iter_1": 2, "eliminated_entailed_constraints": 2578, "eliminated_equality_constraints": 282665, "eliminated_constraints_by_icse": 420652, "eliminated_constraints_by_as": 3962, "icse_fixpoint_iterations": 3, "eliminated_variables": 711843, "preprocessing_fixpoint_iterations": 2, "variables_after_simplification": 253021, "constraints_after_simplification": 258180, "num_constants": 2080, "num_infinite_domains": 0, "sum_props_of_vars": 636018, "sum_props_of_vars": 2544072, "avg_constraints_per_unassigned_var": 2.534532, "max_constraints_per_unassigned_var": 3914, "num_vars_in_2_constraints": 244799, "num_vars_in_3_constraints": 2147, "num_vars_in_4_to_10_constraints": 344, "num_vars_in_more_than_10_constraints": 2820, "sum_domain_size": 3842982965, "sum_domain_size": 480372870, "largest_domain": 191739001, "num_2bits_vars": 179730, "num_64bits_vars": 246575, "num_128bits_vars": 246575, "num_256bits_vars": 246575, "num_512bits_vars": 246575, "num_65536bits_vars": 250888, "num_op_add": 59199, "num_op_mul": 14000, "num_op_min": 55120, "num_op_max": 16590, "num_op_ediv": 0, "num_op_emod": 0, "num_op_eq": 0, "num_op_neq": 0, "num_op_leq": 0, "num_op_gt": 0, "num_op_reified_eq": 1579, "num_op_reified_leq": 111692, "preprocessing_time": 28.082}}
{"type": "statistics", "statistics": {"memory_configuration": "global", "shared_mem": 0, "store_mem": 2024240, "propagator_mem": 4131008}}
{"type": "comment", "comment": "% ERROR: CUDA kernel failed due to an illegal memory access. This might be due to a stack overflow because it is too small. Try increasing the stack size with the options -stack. If it does not work, please report it as a bug.\n"}
{"type": "status", "status": "ERROR", "time": 45431}
{"type": "statistics", "statistics": {"nSolutions": 0}}
{"type": "statistics", "statistics": {"heap_memory": 1836387528}}
srun: error: x1002c4s1b1n0: task 0: Exited with exit code 1
{"type": "lattice-land", "lattice-land": "start"}
{"type": "statistics", "statistics": {"configuration": "turbo-gpu-release_v1.2.8_barebones_wac1_4096_aircraft_B737NG-600-02-Anon.json_1cores_132threads_timeout1200000ms_sub_15", "problem": "aircraft-disassembly", "model": "../data/mzn-challenge/2024/aircraft-disassembly/aircraft.mzn", "data_file": "../data/mzn-challenge/2024/aircraft-disassembly/B737NG-600-02-Anon.json.dzn", "mzn_solver": "turbo.gpu.release", "version": "v1.2.8", "timeout_ms": "1200000", "datetime": "2025-03-30T07:47:18.097768", "status": "UNKNOWN", "cores": "1", "threads": "132", "arch": "barebones", "fixpoint": "wac1", "wac1_threshold": "4096"}}
cpu-bind=MASK - x1002c7s1b1n0, task  0  0 [162585]: mask 0x1 set
{"type": "statistics", "statistics": {"paths": 0, "flatBoolVars": 170302, "flatIntVars": 57186, "flatBoolConstraints": 64425, "flatIntConstraints": 184405, "evaluatedReifiedConstraints": 113150, "method": "minimize", "flatTime": 16.0604}}
{"type": "statistics", "statistics": {"command_line": "/net/scratch/hscra/plgrid/plgptalbot/lattice-land/turbo/build/gpu-release/turbo -t 1200000 -n 1 -s -arch barebones -or 132 -sub 15 -stack 0 -network_analysis -fp wac1 -wac1_threshold 4096 -version v1.2.8 -hardware 'helios' -cutnodes 0 /tmp/133514/x1002c7s1b1n0/mznfile3ZxRR7.fzn", "parsed_variables": 454765, "parsed_constraints": 533296, "abstract_domain": "pir_itv32_z", "tnf_variables": 964802, "tnf_constraints": 968037, "eliminated_entailed_constraints_fp_iter_1": 2578, "eliminated_equality_constraints_fp_iter_1": 282665, "eliminated_constraints_by_icse_fp_iter_1": 420652, "eliminated_constraints_by_as_fp_iter_1": 3962, "icse_fixpoint_iterations_fp_iter_1": 2, "eliminated_entailed_constraints": 2578, "eliminated_equality_constraints": 282665, "eliminated_constraints_by_icse": 420652, "eliminated_constraints_by_as": 3962, "icse_fixpoint_iterations": 3, "eliminated_variables": 711843, "preprocessing_fixpoint_iterations": 2, "variables_after_simplification": 253021, "constraints_after_simplification": 258180, "num_constants": 2080, "num_infinite_domains": 0, "sum_props_of_vars": 636018, "sum_props_of_vars": 2544072, "avg_constraints_per_unassigned_var": 2.534532, "max_constraints_per_unassigned_var": 3914, "num_vars_in_2_constraints": 244799, "num_vars_in_3_constraints": 2147, "num_vars_in_4_to_10_constraints": 344, "num_vars_in_more_than_10_constraints": 2820, "sum_domain_size": 3842982965, "sum_domain_size": 480372870, "largest_domain": 191739001, "num_2bits_vars": 179730, "num_64bits_vars": 246575, "num_128bits_vars": 246575, "num_256bits_vars": 246575, "num_512bits_vars": 246575, "num_65536bits_vars": 250888, "num_op_add": 59199, "num_op_mul": 14000, "num_op_min": 55120, "num_op_max": 16590, "num_op_ediv": 0, "num_op_emod": 0, "num_op_eq": 0, "num_op_neq": 0, "num_op_leq": 0, "num_op_gt": 0, "num_op_reified_eq": 1579, "num_op_reified_leq": 111692, "preprocessing_time": 28.005}}
{"type": "statistics", "statistics": {"memory_configuration": "global", "shared_mem": 0, "store_mem": 2024240, "propagator_mem": 4131008}}
{"type": "statistics", "statistics": {"heap_memory": 51002736640}}
{"type": "solution", "output": {"json": {  "start" : [0, 4, 20, 22, 38, 40, 44, 48, 60, 64, 64, 69, 65, 65, 66, 66, 67, 67, 68, 70, 72, 72, 73, 74, 74, 75, 76, 78, 78],  "assign" : [[false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false]],  "contrib" : [[[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, false, true], [true, false, true], [false, false, true], [false, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, true], [false, false, true], [false, true, true], [true, false, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [true, false, true], [false, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [true, false, true], [false, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [true, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [true, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [true, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [true, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [true, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [true, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [false, true, true]], [[false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [false, false, false], [true, false, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, true, false], [false, false, true], [false, false, true], [false, true, true], [false, true, true]]],  "overlap" : [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true],  "_objective" : 7989250}}, "sections": ["json"], "time": 1218227}
{"type": "statistics", "statistics": {"problem_path": "/tmp/133514/x1002c7s1b1n0/mznfile3ZxRR7.fzn", "solver": "Turbo", "version": "v1.2.8", "hardware": "helios", "arch": "barebones", "fixpoint": "wac1", "wac1_threshold": 4096, "free_search": "no", "or_nodes": 132, "timeout_ms": 1200000, "threads_per_block": 256, "stack_size": 0, "cuda_version": 12040, "cutnodes": 0, "nodes": 7334091, "failures": 3636233, "variables": 253021, "propagators": 258180, "peakDepth": 535, "initTime": 0.212, "solveTime": 1200.088, "num_solutions": 21, "eps_num_subproblems": 32768, "eps_solved_subproblems": 0, "eps_skipped_subproblems": 0, "num_blocks_done": 0, "fixpoint_iterations": 91406991, "num_deductions": 18247109481516, "solve_time": 0.0, "search_time": 39.597, "fixpoint_time": 1098.209, "transfer_cpu2gpu_time": 0.0, "transfer_gpu2cpu_time": 0.0, "select_fp_functions_time": 33.429, "wait_cpu_time": 0.0, "dive_time": 0.0, "objective": 7989250}}
{"type": "statistics", "statistics": {"nSolutions": 1}}
